# train.py
# E:/MRVNet2D/Restormer + Volterra/train.py

""" import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset
from torchvision import transforms
from tqdm import tqdm
from torch.amp import autocast, GradScaler  # âœ… ìµœì‹  ë²„ì „ ì‚¬ìš©
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from restormer_volterra import RestormerVolterra
from re_dataset.kadid_dataset import KadidDataset
from re_dataset.rain100h_dataset import Rain100HDataset
from re_dataset.gopro_dataset import GoProDataset
from re_dataset.sidd_dataset import SIDD_Dataset

# âœ… í•™ìŠµ ì„¤ì •
BATCH_SIZE = 2
EPOCHS = 100
LR = 2e-4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# âœ… ê²½ë¡œ ì„¤ì •
KADID_CSV = 'E:/restormer+volterra/data/KADID10K/kadid10k.csv'
RAIN100H_DIR = 'E:/restormer+volterra/data/rain100H/train'
GOPRO_CSV = 'E:/restormer+volterra/data/GOPRO_Large/gopro_train_pairs.csv'
SIDD_DIR = 'E:/restormer+volterra/data/SIDD'

SAVE_DIR = 'checkpoints/restormer_volterra_train_4sets'
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… Progressive Learning ìŠ¤ì¼€ì¤„
resize_schedule = {
    0: 128,
    30: 192,
    60: 256
}

def get_transform(epoch):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor()
    ])

def main():
    model = RestormerVolterra().to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device='cuda')

    for epoch in range(EPOCHS):
        transform = get_transform(epoch)

        # âœ… ë°ì´í„°ì…‹ ë¡œë“œ
        kadid_dataset = KADID10KDataset(csv_file=KADID_CSV, transform=transform)
        rain100h_dataset = Rain100HDataset(root_dir=RAIN100H_DIR, transform=transform)
        gopro_dataset = GoProDataset(csv_path=GOPRO_CSV, transform=transform)
        sidd_dataset = SIDD_Dataset(root_dir=SIDD_DIR, transform=transform)

        # âœ… ë°ì´í„°ì…‹ í†µí•©
        train_dataset = ConcatDataset([
            kadid_dataset,
            rain100h_dataset,
            gopro_dataset,
            sidd_dataset
        ])

        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                  shuffle=True, num_workers=4, pin_memory=True)

        print(f"[Epoch {epoch+1}] Input resolution: {transform.transforms[0].size}, Total samples: {len(train_dataset)}")

        model.train()
        epoch_loss = 0
        total_psnr, total_ssim, count = 0.0, 0.0, 0
        loop = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{EPOCHS}]", leave=False)

        for distorted, reference in loop:
            distorted, reference = distorted.to(DEVICE), reference.to(DEVICE)
            optimizer.zero_grad()

            with autocast(device_type='cuda'):
                output = model(distorted)
                loss = criterion(output, reference)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()

            # âœ… PSNR / SSIM ê³„ì‚° (batch ë‚´ ì²« ìƒ˜í”Œ ê¸°ì¤€)
            out_np = output[0].detach().cpu().numpy().transpose(1, 2, 0)
            ref_np = reference[0].detach().cpu().numpy().transpose(1, 2, 0)

            psnr = compute_psnr(ref_np, out_np, data_range=1.0)
            ssim = compute_ssim(ref_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=loss.item(), psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {epoch_loss / len(train_loader):.6f} | "
              f"Avg PSNR: {total_psnr / count:.2f} | Avg SSIM: {total_ssim / count:.4f}")

        # âœ… ëª¨ë¸ ì €ì¥
        torch.save(model.state_dict(), os.path.join(SAVE_DIR, f"epoch_{epoch+1}.pth"))

if __name__ == '__main__':
    main() """



"""
ì…ë ¥ í•´ìƒë„: 256Ã—256Ã—C

Encoder íë¦„:

L1: 256Ã—256Ã—C

L2: 128Ã—128Ã—2C

L3: 64Ã—64Ã—4C

L4: 32Ã—32Ã—8C

Decoder íë¦„:

L3: 64Ã—64Ã—4C

L2: 128Ã—128Ã—2C

L1: 256Ã—256Ã—C

ìµœì¢… ì¶œë ¥: 256Ã—256Ã—C

ì¦‰, **ì…ë ¥ê³¼ ì¶œë ¥ì€ ë™ì¼ í•´ìƒë„ (256Ã—256)**ì´ë©°, encoderëŠ” 4ë‹¨ê³„ downsampling, decoderëŠ” 3ë‹¨ê³„ upsampling êµ¬ì¡°ì…ë‹ˆë‹¤.

"""

# ì´ì–´ì„œ í•™ìŠµ
# train.py
# E:/MRVNet2D/Restormer + Volterra/train.py

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset
from torchvision import transforms
from tqdm import tqdm
from torch.amp import autocast, GradScaler
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from restormer_volterra import RestormerVolterra
from kadid_dataset import KADID10KDataset
from re_dataset.rain100h_dataset import Rain100HDataset
from re_dataset.gopro_dataset import GoProDataset
from re_dataset.sidd_dataset import SIDD_Dataset

# âœ… ì„¤ì •
BATCH_SIZE = 2
EPOCHS = 100
LR = 2e-4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# âœ… ê²½ë¡œ
KADID_CSV = 'E:/restormer+volterra/data/KADID10K/kadid10k.csv'
RAIN100H_DIR = 'E:/restormer+volterra/data/rain100H/train'
GOPRO_CSV = 'E:/restormer+volterra/data/GOPRO_Large/gopro_train_pairs.csv'
SIDD_DIR = 'E:/restormer+volterra/data/SIDD'
SAVE_DIR = 'checkpoints/restormer_volterra_train_4sets'
CHECKPOINT_PATH = os.path.join(SAVE_DIR, 'epoch_97.pth')
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… Progressive Learning
resize_schedule = {
    0: 128,
    30: 192,
    60: 256
}

def get_transform(epoch):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor()
    ])

def main():
    model = RestormerVolterra().to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device='cuda')

    resume_epoch = 0

    # âœ… ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ë©´ ì´ì–´ì„œ í•™ìŠµ
    if os.path.exists(CHECKPOINT_PATH):
        print(f"ğŸ” Loading checkpoint from {CHECKPOINT_PATH}")
        checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)
        model.load_state_dict(checkpoint)
        resume_epoch = 97  # ìˆ˜ë™ ì„¤ì • (íŒŒì¼ëª… ê¸°ì¤€)

    criterion = nn.MSELoss()

    for epoch in range(resume_epoch, EPOCHS):
        transform = get_transform(epoch)

        # âœ… ë°ì´í„°ì…‹
        kadid_dataset = KADID10KDataset(csv_file=KADID_CSV, transform=transform)
        rain100h_dataset = Rain100HDataset(root_dir=RAIN100H_DIR, transform=transform)
        gopro_dataset = GoProDataset(csv_path=GOPRO_CSV, transform=transform)
        sidd_dataset = SIDD_Dataset(root_dir=SIDD_DIR, transform=transform)

        train_dataset = ConcatDataset([kadid_dataset, rain100h_dataset, gopro_dataset, sidd_dataset])
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)

        print(f"[Epoch {epoch+1}] Input resolution: {transform.transforms[0].size}, Total samples: {len(train_dataset)}")

        model.train()
        epoch_loss = 0
        total_psnr, total_ssim, count = 0.0, 0.0, 0
        loop = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{EPOCHS}]", leave=False)

        for distorted, reference in loop:
            distorted, reference = distorted.to(DEVICE), reference.to(DEVICE)
            optimizer.zero_grad()

            with autocast(device_type='cuda'):
                output = model(distorted)
                loss = criterion(output, reference)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()

            # PSNR/SSIM (batch ì²« ìƒ˜í”Œ ê¸°ì¤€)
            out_np = output[0].detach().cpu().numpy().transpose(1, 2, 0)
            ref_np = reference[0].detach().cpu().numpy().transpose(1, 2, 0)

            psnr = compute_psnr(ref_np, out_np, data_range=1.0)
            ssim = compute_ssim(ref_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=loss.item(), psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {epoch_loss / len(train_loader):.6f} | "
              f"Avg PSNR: {total_psnr / count:.2f} | Avg SSIM: {total_ssim / count:.4f}")

        # âœ… ì €ì¥
        torch.save(model.state_dict(), os.path.join(SAVE_DIR, f"epoch_{epoch+1}.pth"))

if __name__ == '__main__':
    main()

# ğŸ† Best Epoch: 97 | PSNR: 28.76 | SSIM: 0.8687
