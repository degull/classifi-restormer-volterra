# restore_kadid
""" import os
import torch
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from restormer_volterra import RestormerVolterra
from torch.cuda.amp import autocast
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\restormer+volterra\checkpoints\restormer_volterra_train_4sets\epoch_100.pth"
DISTORTED_DIR = r"E:\restormer+volterra\data\KADID10K\images"
SAVE_DIR = r"E:\restormer+volterra\results\restored_kadid"
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ë¼ë²¨ ì¶”ê°€ í•¨ìˆ˜
def add_label(img, text):
    labeled = Image.new("RGB", (256, 280), (255, 255, 255))  # ìœ„ ê³µê°„ ì¶”ê°€
    labeled.paste(img, (0, 24))
    draw = ImageDraw.Draw(labeled)
    font = ImageFont.load_default()
    text_width = draw.textlength(text, font=font)
    draw.text(((256 - text_width) // 2, 4), text, fill=(0, 0, 0), font=font)
    return labeled

# âœ… í´ë” ìˆœíšŒ
for filename in os.listdir(DISTORTED_DIR):
    # macOS ë©”íƒ€íŒŒì¼, ìˆ¨ê¹€íŒŒì¼, í™•ì¥ì ê²€ì‚¬
    if not (filename.lower().endswith((".png", ".jpg", ".jpeg", ".bmp"))) or filename.startswith("._"):
        continue
    if "_" not in filename:  # ì°¸ì¡° ì´ë¯¸ì§€ì¼ ê²½ìš° ìŠ¤í‚µ
        continue

    distorted_path = os.path.join(DISTORTED_DIR, filename)
    ref_name = filename.split("_")[0] + ".png"
    reference_path = os.path.join(DISTORTED_DIR, ref_name)
    save_path = os.path.join(SAVE_DIR, filename.replace(".", "_restored."))

    # âœ… ì´ë¯¸ì§€ ë¡œë“œ
    distorted_pil = Image.open(distorted_path).convert("RGB").resize((256, 256))
    distorted_tensor = transform(distorted_pil).unsqueeze(0).to(DEVICE)

    reference_exists = os.path.exists(reference_path)
    if reference_exists:
        reference_pil = Image.open(reference_path).convert("RGB").resize((256, 256))
        reference_tensor = transform(reference_pil).unsqueeze(0).to(DEVICE)

    # âœ… ë³µì› ìˆ˜í–‰
    with torch.no_grad():
        with autocast():
            restored_tensor = model(distorted_tensor)

    # âœ… ë³€í™˜
    distorted_np = distorted_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
    restored_np = restored_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
    distorted_np = np.clip(distorted_np, 0, 1)
    restored_np = np.clip(restored_np, 0, 1)

    dist_img = Image.fromarray((distorted_np * 255).astype(np.uint8))
    restored_img = Image.fromarray((restored_np * 255).astype(np.uint8))

    dist_labeled = add_label(dist_img, "Distorted")
    restored_labeled = add_label(restored_img, "Restored")

    # âœ… ë¼ë²¨ í¬í•¨ ì´ë¯¸ì§€ ê²°í•©
    if reference_exists:
        reference_np = reference_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        reference_np = np.clip(reference_np, 0, 1)
        ref_img = Image.fromarray((reference_np * 255).astype(np.uint8))
        ref_labeled = add_label(ref_img, "Reference")

        # PSNR/SSIM ì¶œë ¥
        psnr_dist = compute_psnr(reference_np, distorted_np, data_range=1.0)
        ssim_dist = compute_ssim(reference_np, distorted_np, data_range=1.0, channel_axis=2)
        psnr_rest = compute_psnr(reference_np, restored_np, data_range=1.0)
        ssim_rest = compute_ssim(reference_np, restored_np, data_range=1.0, channel_axis=2)

        print(f"ğŸ“Œ {filename} | PSNR (Dist): {psnr_dist:.2f}, SSIM (Dist): {ssim_dist:.3f} | "
              f"PSNR (Rest): {psnr_rest:.2f}, SSIM (Rest): {ssim_rest:.3f}")

        final = Image.new("RGB", (256 * 3, 280))
        final.paste(ref_labeled, (0, 0))
        final.paste(dist_labeled, (256, 0))
        final.paste(restored_labeled, (512, 0))
    else:
        print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ì—†ìŒ: {reference_path}")
        final = Image.new("RGB", (256 * 2, 280))
        final.paste(dist_labeled, (0, 0))
        final.paste(restored_labeled, (256, 0))

    final.save(save_path)

print(f"\nâœ… ì „ì²´ ë³µì› ì™„ë£Œ. ì €ì¥ ê²½ë¡œ: {SAVE_DIR}")
 """

# restore_tid2013.py
""" import os
import torch
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from restormer_volterra import RestormerVolterra
from torch.cuda.amp import autocast
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\restormer+volterra\checkpoints\restormer_volterra_train_4sets\epoch_100.pth"
DISTORTED_DIR = r"E:\restormer+volterra\data\tid2013\distorted_images"
REFERENCE_DIR = r"E:\restormer+volterra\data\tid2013\reference_images"
SAVE_DIR = r"E:\restormer+volterra\results\restored_tid"
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ë¼ë²¨ ì¶”ê°€ í•¨ìˆ˜
def add_label(img, text):
    labeled = Image.new("RGB", (256, 280), (255, 255, 255))  # ìœ„ ê³µê°„ ì¶”ê°€
    labeled.paste(img, (0, 24))
    draw = ImageDraw.Draw(labeled)
    font = ImageFont.load_default()
    text_width = draw.textlength(text, font=font)
    draw.text(((256 - text_width) // 2, 4), text, fill=(0, 0, 0), font=font)
    return labeled

# âœ… ë³µì› ë£¨í”„
for filename in os.listdir(DISTORTED_DIR):
    if not filename.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")) or filename.startswith("._"):
        continue

    distorted_path = os.path.join(DISTORTED_DIR, filename)
    ref_id = filename.split("_")[0].lower()  # e.g., i01
    ref_name = ref_id.replace("i", "I") + ".BMP"  # e.g., I01.BMP
    reference_path = os.path.join(REFERENCE_DIR, ref_name)
    save_path = os.path.join(SAVE_DIR, filename.replace(".", "_restored."))

    try:
        distorted_pil = Image.open(distorted_path).convert("RGB").resize((256, 256))
        distorted_tensor = transform(distorted_pil).unsqueeze(0).to(DEVICE)
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {distorted_path} ({e})")
        continue

    reference_exists = os.path.exists(reference_path)
    if reference_exists:
        reference_pil = Image.open(reference_path).convert("RGB").resize((256, 256))
        reference_tensor = transform(reference_pil).unsqueeze(0).to(DEVICE)

    # âœ… ë³µì› ìˆ˜í–‰
    with torch.no_grad():
        with autocast():
            restored_tensor = model(distorted_tensor)

    # âœ… ë³€í™˜
    distorted_np = distorted_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
    restored_np = restored_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
    distorted_np = np.clip(distorted_np, 0, 1)
    restored_np = np.clip(restored_np, 0, 1)

    dist_img = Image.fromarray((distorted_np * 255).astype(np.uint8))
    restored_img = Image.fromarray((restored_np * 255).astype(np.uint8))

    dist_labeled = add_label(dist_img, "Distorted")
    restored_labeled = add_label(restored_img, "Restored")

    # âœ… ë¼ë²¨ í¬í•¨ ì´ë¯¸ì§€ ê²°í•©
    if reference_exists:
        reference_np = reference_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        reference_np = np.clip(reference_np, 0, 1)
        ref_img = Image.fromarray((reference_np * 255).astype(np.uint8))
        ref_labeled = add_label(ref_img, "Reference")

        # PSNR/SSIM ì¶œë ¥
        psnr_dist = compute_psnr(reference_np, distorted_np, data_range=1.0)
        ssim_dist = compute_ssim(reference_np, distorted_np, data_range=1.0, channel_axis=2)
        psnr_rest = compute_psnr(reference_np, restored_np, data_range=1.0)
        ssim_rest = compute_ssim(reference_np, restored_np, data_range=1.0, channel_axis=2)

        print(f"ğŸ“Œ {filename} | PSNR (Dist): {psnr_dist:.2f}, SSIM (Dist): {ssim_dist:.3f} | "
              f"PSNR (Rest): {psnr_rest:.2f}, SSIM (Rest): {ssim_rest:.3f}")

        final = Image.new("RGB", (256 * 3, 280))
        final.paste(ref_labeled, (0, 0))
        final.paste(dist_labeled, (256, 0))
        final.paste(restored_labeled, (512, 0))
    else:
        print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ì—†ìŒ: {reference_path}")
        final = Image.new("RGB", (256 * 2, 280))
        final.paste(dist_labeled, (0, 0))
        final.paste(restored_labeled, (256, 0))

    final.save(save_path)

print(f"\nâœ… ì „ì²´ ë³µì› ì™„ë£Œ. ì €ì¥ ê²½ë¡œ: {SAVE_DIR}")
 """

# restore_csiq
""" import os
import torch
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from restormer_volterra import RestormerVolterra
from torch.cuda.amp import autocast
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\restormer+volterra\checkpoints\restormer_volterra_train_4sets\epoch_100.pth"
DISTORTED_ROOT = r"E:\restormer+volterra\data\CSIQ\dst_imgs"
REFERENCE_DIR = r"E:\restormer+volterra\data\CSIQ\src_imgs"
SAVE_DIR = r"E:\restormer+volterra\results\restored_csiq"
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ë¼ë²¨ ì¶”ê°€ í•¨ìˆ˜
def add_label(img, text):
    labeled = Image.new("RGB", (256, 280), (255, 255, 255))
    labeled.paste(img, (0, 24))
    draw = ImageDraw.Draw(labeled)
    font = ImageFont.load_default()
    text_width = draw.textlength(text, font=font)
    draw.text(((256 - text_width) // 2, 4), text, fill=(0, 0, 0), font=font)
    return labeled

# âœ… ì „ì²´ ì™œê³¡ í´ë” ìˆœíšŒ
for distortion_type in os.listdir(DISTORTED_ROOT):
    subdir = os.path.join(DISTORTED_ROOT, distortion_type)
    if not os.path.isdir(subdir):
        continue

    print(f"ğŸ“‚ ë³µì› ì‹œì‘: {distortion_type}")
    save_subdir = os.path.join(SAVE_DIR, distortion_type)
    os.makedirs(save_subdir, exist_ok=True)

    for filename in os.listdir(subdir):
        if not filename.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")) or filename.startswith("._"):
            continue

        distorted_path = os.path.join(subdir, filename)
        reference_name = filename.split('.')[0].split('_')[0] + ".png"
        reference_path = os.path.join(REFERENCE_DIR, reference_name)
        save_path = os.path.join(save_subdir, filename.replace(".", "_restored."))

        # âœ… ì´ë¯¸ì§€ ë¡œë“œ
        try:
            distorted_pil = Image.open(distorted_path).convert("RGB").resize((256, 256))
        except:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {distorted_path}")
            continue

        distorted_tensor = transform(distorted_pil).unsqueeze(0).to(DEVICE)
        reference_exists = os.path.exists(reference_path)

        if reference_exists:
            reference_pil = Image.open(reference_path).convert("RGB").resize((256, 256))
            reference_tensor = transform(reference_pil).unsqueeze(0).to(DEVICE)

        # âœ… ë³µì› ìˆ˜í–‰
        with torch.no_grad():
            with autocast():
                restored_tensor = model(distorted_tensor)

        # âœ… ë³€í™˜
        distorted_np = distorted_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        restored_np = restored_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        distorted_np = np.clip(distorted_np, 0, 1)
        restored_np = np.clip(restored_np, 0, 1)

        dist_img = Image.fromarray((distorted_np * 255).astype(np.uint8))
        restored_img = Image.fromarray((restored_np * 255).astype(np.uint8))

        dist_labeled = add_label(dist_img, "Distorted")
        restored_labeled = add_label(restored_img, "Restored")

        # âœ… ë¼ë²¨ í¬í•¨ ì´ë¯¸ì§€ ê²°í•©
        if reference_exists:
            reference_np = reference_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            reference_np = np.clip(reference_np, 0, 1)
            ref_img = Image.fromarray((reference_np * 255).astype(np.uint8))
            ref_labeled = add_label(ref_img, "Reference")

            psnr_dist = compute_psnr(reference_np, distorted_np, data_range=1.0)
            ssim_dist = compute_ssim(reference_np, distorted_np, data_range=1.0, channel_axis=2)
            psnr_rest = compute_psnr(reference_np, restored_np, data_range=1.0)
            ssim_rest = compute_ssim(reference_np, restored_np, data_range=1.0, channel_axis=2)

            print(f"ğŸ“Œ {filename} | PSNR (Dist): {psnr_dist:.2f}, SSIM (Dist): {ssim_dist:.3f} | "
                  f"PSNR (Rest): {psnr_rest:.2f}, SSIM (Rest): {ssim_rest:.3f}")

            final = Image.new("RGB", (256 * 3, 280))
            final.paste(ref_labeled, (0, 0))
            final.paste(dist_labeled, (256, 0))
            final.paste(restored_labeled, (512, 0))
        else:
            print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ì—†ìŒ: {reference_path}")
            final = Image.new("RGB", (256 * 2, 280))
            final.paste(dist_labeled, (0, 0))
            final.paste(restored_labeled, (256, 0))

        final.save(save_path)

print(f"\nâœ… CSIQ ì „ì²´ ë³µì› ì™„ë£Œ. ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {SAVE_DIR}")
 """

# restore_rain100l
""" import os
import torch
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from restormer_volterra import RestormerVolterra
from torch.cuda.amp import autocast
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\restormer+volterra\checkpoints\restormer_volterra_train_4sets\epoch_100.pth"
RAIN_ROOT = r"E:\restormer+volterra\data\rain100L"
SAVE_DIR = r"E:\restormer+volterra\results\restored_rain100L"
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ë¼ë²¨ í•¨ìˆ˜
def add_label(img, text):
    labeled = Image.new("RGB", (256, 280), (255, 255, 255))
    labeled.paste(img, (0, 24))
    draw = ImageDraw.Draw(labeled)
    font = ImageFont.load_default()
    text_width = draw.textlength(text, font=font)
    draw.text(((256 - text_width) // 2, 4), text, fill=(0, 0, 0), font=font)
    return labeled

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ë³µì› í•¨ìˆ˜
def process_split(split):
    rain_dir = os.path.join(RAIN_ROOT, split, "rain")
    norain_dir = os.path.join(RAIN_ROOT, split, "norain")
    save_subdir = os.path.join(SAVE_DIR, split)
    os.makedirs(save_subdir, exist_ok=True)

    for filename in os.listdir(rain_dir):
        if not filename.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")) or filename.startswith("._"):
            continue

        rain_path = os.path.join(rain_dir, filename)
        norain_path = os.path.join(norain_dir, filename)
        save_path = os.path.join(save_subdir, filename.replace(".", "_restored."))

        try:
            rain_pil = Image.open(rain_path).convert("RGB").resize((256, 256))
        except:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {rain_path}")
            continue

        rain_tensor = transform(rain_pil).unsqueeze(0).to(DEVICE)
        has_ref = os.path.exists(norain_path)
        if has_ref:
            ref_pil = Image.open(norain_path).convert("RGB").resize((256, 256))
            ref_tensor = transform(ref_pil).unsqueeze(0).to(DEVICE)

        # ë³µì›
        with torch.no_grad():
            with autocast():
                restored_tensor = model(rain_tensor)

        rain_np = rain_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        restored_np = restored_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        rain_np = np.clip(rain_np, 0, 1)
        restored_np = np.clip(restored_np, 0, 1)

        rain_img = Image.fromarray((rain_np * 255).astype(np.uint8))
        restored_img = Image.fromarray((restored_np * 255).astype(np.uint8))
        rain_labeled = add_label(rain_img, "Distorted")
        restored_labeled = add_label(restored_img, "Restored")

        if has_ref:
            ref_np = ref_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            ref_np = np.clip(ref_np, 0, 1)
            ref_img = Image.fromarray((ref_np * 255).astype(np.uint8))
            ref_labeled = add_label(ref_img, "Reference")

            psnr_dist = compute_psnr(ref_np, rain_np, data_range=1.0)
            ssim_dist = compute_ssim(ref_np, rain_np, data_range=1.0, channel_axis=2)
            psnr_rest = compute_psnr(ref_np, restored_np, data_range=1.0)
            ssim_rest = compute_ssim(ref_np, restored_np, data_range=1.0, channel_axis=2)

            print(f"ğŸ“Œ [{split}] {filename} | PSNR(D): {psnr_dist:.2f}, SSIM(D): {ssim_dist:.3f} | "
                  f"PSNR(R): {psnr_rest:.2f}, SSIM(R): {ssim_rest:.3f}")

            final = Image.new("RGB", (256 * 3, 280))
            final.paste(ref_labeled, (0, 0))
            final.paste(rain_labeled, (256, 0))
            final.paste(restored_labeled, (512, 0))
        else:
            print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ì—†ìŒ: {norain_path}")
            final = Image.new("RGB", (256 * 2, 280))
            final.paste(rain_labeled, (0, 0))
            final.paste(restored_labeled, (256, 0))

        final.save(save_path)

# âœ… ì‹¤í–‰
process_split("train")
process_split("test")

print(f"\nâœ… Rain100L ì „ì²´ ë³µì› ì™„ë£Œ. ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {SAVE_DIR}")
 """

# restore_HIDE
import os
import torch
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from restormer_volterra import RestormerVolterra
from torch.cuda.amp import autocast
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\restormer+volterra\checkpoints\restormer_volterra_train_4sets\epoch_100.pth"
HIDE_ROOT = r"E:\restormer+volterra\data\HIDE"
SAVE_DIR = r"E:\restormer+volterra\results\restored_hide"
os.makedirs(SAVE_DIR, exist_ok=True)

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ë¼ë²¨ í•¨ìˆ˜
def add_label(img, text):
    labeled = Image.new("RGB", (256, 280), (255, 255, 255))
    labeled.paste(img, (0, 24))
    draw = ImageDraw.Draw(labeled)
    font = ImageFont.load_default()
    text_width = draw.textlength(text, font=font)
    draw.text(((256 - text_width) // 2, 4), text, fill=(0, 0, 0), font=font)
    return labeled

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ë³µì› í•¨ìˆ˜
def process_split(split):
    split_dir = os.path.join(HIDE_ROOT, split)
    gt_dir = os.path.join(HIDE_ROOT, "GT")
    save_subdir = os.path.join(SAVE_DIR, split)
    os.makedirs(save_subdir, exist_ok=True)

    for filename in os.listdir(split_dir):
        if not filename.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")) or filename.startswith("._"):
            continue

        distorted_path = os.path.join(split_dir, filename)
        gt_name = filename.replace("from", "from")  # ì´ë¦„ ê·¸ëŒ€ë¡œ ëŒ€ì‘
        gt_path = os.path.join(gt_dir, gt_name)
        save_path = os.path.join(save_subdir, filename.replace(".", "_restored."))

        try:
            distorted_pil = Image.open(distorted_path).convert("RGB").resize((256, 256))
        except:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {distorted_path}")
            continue

        distorted_tensor = transform(distorted_pil).unsqueeze(0).to(DEVICE)
        has_ref = os.path.exists(gt_path)
        if has_ref:
            ref_pil = Image.open(gt_path).convert("RGB").resize((256, 256))
            ref_tensor = transform(ref_pil).unsqueeze(0).to(DEVICE)

        # âœ… ë³µì› ìˆ˜í–‰
        with torch.no_grad():
            with autocast():
                restored_tensor = model(distorted_tensor)

        distorted_np = distorted_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        restored_np = restored_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
        distorted_np = np.clip(distorted_np, 0, 1)
        restored_np = np.clip(restored_np, 0, 1)

        dist_img = Image.fromarray((distorted_np * 255).astype(np.uint8))
        restored_img = Image.fromarray((restored_np * 255).astype(np.uint8))

        dist_labeled = add_label(dist_img, "Distorted")
        restored_labeled = add_label(restored_img, "Restored")

        if has_ref:
            ref_np = ref_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            ref_np = np.clip(ref_np, 0, 1)
            ref_img = Image.fromarray((ref_np * 255).astype(np.uint8))
            ref_labeled = add_label(ref_img, "Reference")

            psnr_dist = compute_psnr(ref_np, distorted_np, data_range=1.0)
            ssim_dist = compute_ssim(ref_np, distorted_np, data_range=1.0, channel_axis=2)
            psnr_rest = compute_psnr(ref_np, restored_np, data_range=1.0)
            ssim_rest = compute_ssim(ref_np, restored_np, data_range=1.0, channel_axis=2)

            print(f"ğŸ“Œ [{split}] {filename} | PSNR(D): {psnr_dist:.2f}, SSIM(D): {ssim_dist:.3f} | "
                  f"PSNR(R): {psnr_rest:.2f}, SSIM(R): {ssim_rest:.3f}")

            final = Image.new("RGB", (256 * 3, 280))
            final.paste(ref_labeled, (0, 0))
            final.paste(dist_labeled, (256, 0))
            final.paste(restored_labeled, (512, 0))
        else:
            print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ì—†ìŒ: {gt_path}")
            final = Image.new("RGB", (256 * 2, 280))
            final.paste(dist_labeled, (0, 0))
            final.paste(restored_labeled, (256, 0))

        final.save(save_path)

# âœ… ì‹¤í–‰
process_split("train")
process_split("test")

print(f"\nâœ… HIDE ì „ì²´ ë³µì› ì™„ë£Œ. ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {SAVE_DIR}")
