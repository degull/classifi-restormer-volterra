# test_single_image.py
# ref o
# [Reference | Distorted | Restored]

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from restormer_volterra import RestormerVolterra
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim
from torch.cuda.amp import autocast

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\MRVNet2D\checkpoints\restormer_volterra_all\epoch_58.pth"

# âœ… ë‹¨ì¼ ì´ë¯¸ì§€ ê²½ë¡œ
DISTORTED_PATH = r"E:\MRVNet2D\dataset\KADID10K\images\I81_21_05.png"
REFERENCE_PATH = r"E:\MRVNet2D\dataset\KADID10K\images\I81.png"
SAVE_PATH = r"E:\MRVNet2D\results\comparison_output.png"

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
distorted_img_pil = Image.open(DISTORTED_PATH).convert("RGB").resize((256, 256))
reference_img_pil = Image.open(REFERENCE_PATH).convert("RGB").resize((256, 256))

distorted_img = transform(distorted_img_pil).unsqueeze(0).to(DEVICE)
reference_img = transform(reference_img_pil).unsqueeze(0).to(DEVICE)

# âœ… ë³µì› ìˆ˜í–‰
with torch.no_grad():
    with autocast():
        restored_img = model(distorted_img)

# âœ… NumPy ë³€í™˜
distorted_np = distorted_img.squeeze(0).cpu().numpy().transpose(1, 2, 0)
reference_np = reference_img.squeeze(0).cpu().numpy().transpose(1, 2, 0)
restored_np = restored_img.squeeze(0).cpu().numpy().transpose(1, 2, 0)

distorted_np = np.clip(distorted_np, 0, 1)
reference_np = np.clip(reference_np, 0, 1)
restored_np = np.clip(restored_np, 0, 1)

# âœ… PSNR / SSIM ê³„ì‚°
psnr_restored = compute_psnr(reference_np, restored_np, data_range=1.0)
ssim_restored = compute_ssim(reference_np, restored_np, data_range=1.0, channel_axis=2)

psnr_distorted = compute_psnr(reference_np, distorted_np, data_range=1.0)
ssim_distorted = compute_ssim(reference_np, distorted_np, data_range=1.0, channel_axis=2)

# âœ… ê²°ê³¼ ì¶œë ¥
print(f"ğŸ“Œ [ì°¸ì¡° vs ì™œê³¡] PSNR: {psnr_distorted:.2f} dB, SSIM: {ssim_distorted:.4f}")
print(f"âœ… [ì°¸ì¡° vs ë³µì›] PSNR: {psnr_restored:.2f} dB, SSIM: {ssim_restored:.4f}")

# âœ… ë‚˜ë€íˆ ì´ë¯¸ì§€ ì €ì¥ (ref | dist | restored)
ref_img = (reference_np * 255).astype(np.uint8)
dist_img = (distorted_np * 255).astype(np.uint8)
restored_img = (restored_np * 255).astype(np.uint8)

ref_pil = Image.fromarray(ref_img)
dist_pil = Image.fromarray(dist_img)
restored_pil = Image.fromarray(restored_img)

concat_img = Image.new('RGB', (256 * 3, 256))
concat_img.paste(ref_pil, (0, 0))
concat_img.paste(dist_pil, (256, 0))
concat_img.paste(restored_pil, (512, 0))
concat_img.save(SAVE_PATH)

print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {SAVE_PATH}")

# ref x
""" 
import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from restormer_volterra import RestormerVolterra
from torch.cuda.amp import autocast

# âœ… ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_PATH = r"E:\MRVNet2D\checkpoints\restormer_volterra_all\epoch_58.pth"

# âœ… ì…ë ¥ ì´ë¯¸ì§€ (ì™œê³¡ ì´ë¯¸ì§€)
DISTORTED_PATH = r"E:\MRVNet2D\dataset\KADID10K\images\I32_03_05.png"
SAVE_PATH = r"E:\MRVNet2D\results\restored_output_only.png"

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# âœ… ëª¨ë¸ ë¡œë“œ
model = RestormerVolterra().to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# âœ… ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
distorted_img_pil = Image.open(DISTORTED_PATH).convert("RGB").resize((256, 256))
distorted_img = transform(distorted_img_pil).unsqueeze(0).to(DEVICE)

# âœ… ë³µì› ìˆ˜í–‰
with torch.no_grad():
    with autocast():
        output = model(distorted_img)

# âœ… ê²°ê³¼ ë³€í™˜ ë° ì €ì¥
output_np = output.squeeze(0).cpu().numpy().transpose(1, 2, 0)
output_np = np.clip(output_np, 0, 1)
restored_img = (output_np * 255).astype(np.uint8)
Image.fromarray(restored_img).save(SAVE_PATH)

print(f"âœ… Restored image saved to: {SAVE_PATH}")
 """